{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpIPMNPoU_-p"
   },
   "source": [
    "# Unsupervised Learning Solution\n",
    "### EDSA - Movie Recommendation 2022 \n",
    "#### AI Incorporated - Team 4 EDSA\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F2205222%2Fbca114f2e4f6b9b46f2cc76527d7401e%2FImage_header.png?generation=1593773828621598&alt=media\" width=100%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "## Table of Content\n",
    "\n",
    "<a href=#one>1. Introduction</a>\n",
    "\n",
    "    1.1 Overview\n",
    "    1.2 Problem Statement\n",
    "    1.3 Model Versioning with COMET\n",
    "    1.4 Required Installations\n",
    "       \n",
    "<a href=#two>1. Import Packages</a>\n",
    "\n",
    "<a href=#three>2. Collect Data</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)<a>\n",
    "    \n",
    "    4.1 \n",
    "\n",
    "<a href=#five>5. Data Processing</a>\n",
    "    \n",
    "    5.1 \n",
    "\n",
    "<a href=#six>6. Feature Engineering</a>\n",
    "\n",
    "<a href=#seven>7. Modelling</a>\n",
    "    \n",
    "    7.1 \n",
    "\n",
    "<a href=#eight>8. Model Performance</a>\n",
    "    \n",
    "    8.1 \n",
    "\n",
    "<a href=#nine>9. Saving & Exporting Model</a>\n",
    "    \n",
    "    9.1 Export Test Prediction as CSV\n",
    "    9.2 Log to Comet\n",
    "\n",
    "<a href=#ten>10. Conclusion</a>\n",
    "\n",
    "<a href=#eleven>11. Recommendation</a>\n",
    "\n",
    "<a href=#ref>Reference Document Links</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. INTRODUCTION\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Overview\n",
    "\n",
    "In today’s technology driven world, recommender systems are socially and economically critical to ensure that individuals can make optimised choices surrounding the content they engage with on a daily basis. One application where this is especially true is movie recommendations; where intelligent algorithms can help viewers find great titles from tens of thousands of options.\n",
    "\n",
    "Hence, We will be constructing a recommendation algorithm based on `Content` and `Collaborative` filtering, capable of accurately predicting how a user will rate a movie they have not yet viewed, based on their historical preferences.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*odvftNNQJp3O6vpwmZsJOQ.png\" width=100%/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Problem Statement\n",
    "\n",
    "In this era of Artifical Intelligence, Everthing from the Government to Education down to the ever growing entertainment industry now realies on AI tech to boost their Efficiency. Organisations using recommender systems focus on increasing sales and deliveries as a result of very personalized offers and an enhanced customer experience.\n",
    "\n",
    "Hence, we will be providing an accurate and robust solution to this challenge has immense economic potential, with users of the system being personalised recommendations - generating platform affinity for the streaming services which best facilitates their audience's viewing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Model Versioning with COMET\n",
    "\n",
    "To Begin with, We will be using Comet, a great tool for model versioning and experimentation as it records the parameters and conditions from each of your experiements- allowing us to reproduce your results, or go back to a previous version of our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Comet\n",
    "# !pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGo ahead and get your api_key, project_name & workspace from your\\nComet Project Folder.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Comet package\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Setting the API key\n",
    "\n",
    "# experiment = Experiment(\n",
    "#     api_key=\"__________\",\n",
    "#     project_name=\"____________\",\n",
    "#     workspace=\"________\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C68jzOFpU_-2"
   },
   "source": [
    "####  1.4 Required Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, Let's Proceed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKmhMwlDU_-u"
   },
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. IMPORT PACKAGES\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "In this section, we will be importing libraries which are a collections of modules in their classes and based on their functionality. For this Analysis and Modelling, we wil be requiring;\n",
    "\n",
    "   ` For Data Manupulation, libraries such as Pandas, Numpy etc.`\n",
    "   \n",
    "`For Data Visualization, libraries such as mathplotlib, seaborn`\n",
    "    \n",
    "`libraries for data prepartion, feature selection, model building, Performance Calculation and more.`\n",
    "\n",
    "**SEE** in-line comments BELOW for purpose per importation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQm0O5XHU_-z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "For a seamless run, \n",
    "All required libraries will be imported here. \n",
    "\"\"\"\n",
    "\n",
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd                                                   # for loading CSV data\n",
    "import numpy as np                                                    # Used for mathematical operations\n",
    "import matplotlib.pyplot as plt                                       # for Graphical Representation                                                 \n",
    "import seaborn as sns                                                 # for specialized plots\n",
    "import re                                                             # for handling Regular expressions                                                           \n",
    "sns.set()                                                             # set plot style\n",
    "\n",
    "# Libraries for data preparation\n",
    "\n",
    "\n",
    "# Libraries for Feature Extraction\n",
    "\n",
    "\n",
    "# Libraries for Model Building\n",
    "\n",
    "\n",
    "# Libraries for calculating performance metrics\n",
    "import time\n",
    "\n",
    "# Libraries to Save/Restore Models\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Collect Data\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "This dataset consists of several million 5-star ratings obtained from users of the online MovieLens movie recommendation service. The MovieLens dataset has long been used by industry and academic researchers to improve the performance of explicitly-based recommender systems, and now you get to as well!\n",
    "\n",
    "Data available on [Kaggle](https://www.kaggle.com/competitions/edsa-movie-recommendation-2022/data)\n",
    "\n",
    "We'll be using a special version of the MovieLens dataset which is enriched with additional data, and resampled for fair evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "This includes looking to understand patterns in our data, pinpoint any outliers and indicate relationships between variables. This phase we will be carrying out some data analysis, descriptive statistics and data visualisations, all in the bid to understand to properly fine refining the data in the feature engineering in preparation for modeling. \n",
    "\n",
    "Hence, let's proceed to carrying out some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to confirm count of null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. DATA PROCESSING\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "The primary funtion of data processing is to provide Faster, higher-quality data, which is key to any successesful model building, and also enabling more valuable insights to be extracted as well. Therefore, Let's commence processing and cleaning our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Feature Engineering\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "This involves preparations to make ready our data to serve those structured selected features to models upon request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Modeling\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "There are several modelling techniques we can apply as classifiers, and of the vast options, we will be trying;\n",
    "\n",
    "`1. Base Model: ` Description..... \n",
    "\n",
    "`2. Model 2: ` Description..... \n",
    "\n",
    "`3. Model 3 `Description..... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "## 8. MODEL PERFORMANCE\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Here will be reviewing the individual performance of our machine learning model and why to use one in place of the other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Model Testing Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Best Model Resolution\n",
    "\n",
    "From the Result we can conclusively say .............."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3 Hypertune Best Model\n",
    "\n",
    "For every model, our goal is to minimize the error or say to have classification or predictions as close as possible to actual values. This is one of the cores or say the major objective of hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline for the gridsearch\n",
    "\n",
    "# set parameter grid\n",
    "# param_grid = { }  \n",
    "\n",
    "# hyper_best_model = Pipeline([ ])\n",
    "\n",
    "# # Fiting data to Best Model \n",
    "# hyper_best_model.fit(X_train, y_train) \n",
    "\n",
    "# # predicting the fit on validation set\n",
    "# y_pred = hyper_best_model.predict(X_val)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model Score in %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4 Best Model Visual Evaluation\n",
    "Measuring the effectiveness and performance is what exactly the confusion matrix is design to do. So we will be putting this up bot in Numbers and visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nine\"></a>\n",
    "## 9. SAVING & EXPORTING MODEL\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Now, we don't want our models just be sitting in some jupyter notebook, at this point, Let's save results to desired format, preferrably CSV and model as a pickle file. This will be used for deployment purposes to solving real life scenerios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Export Test Prediction as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUnhash to Run \\n(CTRL + /)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Unhash to Run \n",
    "(CTRL + /)\n",
    "'''\n",
    "\n",
    "# X_test = vect.transform(df_test['message']) \n",
    "# test_pred = hyper_best_model.predict(X_test)\n",
    "# save_df = pd.DataFrame(test_pred, columns=['sentiment'])\n",
    "# output=pd.DataFrame({'tweetid': df_test['tweetid']})\n",
    "# submission=output.join(save_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('submission_hyper.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model as pickle file\n",
    "\n",
    "# model_save_path = \"1.0_EDSA_T4_Content_Recommender.pkl\"\n",
    "# with open(model_save_path,'wb') as file:\n",
    "#     pickle.dump(hyper_best_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Log to Comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries for the data we want to log\n",
    "# This had to be defined since that applied to our model is the best from the grid search.\n",
    "\n",
    "# params ={\"random_state\": 42,\n",
    "#          \"model_type \": \"LogisticsRegression\",\n",
    "#          \"Bag of words\": \"Count_Vectorizer\",\n",
    "#          \"C\": 0.1,\n",
    "#          \"min_df\": 1,\n",
    "#          \"max_df\": 0.9,\n",
    "#          \"n_grams\": \"(1, 2)\"\n",
    "#         }\n",
    "\n",
    "# nb_metrics ={\"Accuracy\": metrics.accuracy_score(y_val_en, y_pred),\n",
    "#              \"recall\": metrics.recall_score(y_val_en, y_pred, average='micro'),\n",
    "#              \"f1\": metrics.f1_score(y_val_en, y_pred, average='micro'),\n",
    "#             }\n",
    "\n",
    "# confusionmatrix = confusion_matrix(y_val_en, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log parameters and results\n",
    "# experiment.log_parameters(params)\n",
    "# experiment.log_metrics(nb_metrics)\n",
    "# experiment.log_notebook('5.0 Advance_Classification_Notebook.ipynb', overwrite=False)\n",
    "# experiment.log_confusion_matrix(labels=[\"News\", \"pro\", \"Neutral\",\"Anti\"], matrix=confusionmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: It is required If using comet within a jupyter notebook, to end our experiment on completion as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRICTLY FOR LOCAL JUPYTER NOTEBOOKS\n",
    "# experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly [Go to Streamlite Webpage](http://) to test-run an actual perfromance of our model on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ten\"></a>\n",
    "## 10. Conclusion\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "   In summary ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eleven\"></a>\n",
    "## 11. Recommendation\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "## Reference Links\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [EXPLORE Data Science Academy Resources](https://explore-datascience.net/)\n",
    "* [GitHub Collab Ref.](https://github.com/)\n",
    "* [Commet Collab Ref](https://www.comet.ml/) \n",
    "* [Kaggle Collab Ref](https://www.kaggle.com/competitions/edsa-movie-recommendation-2022/overview)\n",
    "* [How to Build a Movie Recommendation System by Ramya Vidiyala](https://towardsdatascience.com/how-to-build-a-movie-recommendation-system-67e321339109)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VCXae5QXU__Z",
    "wzM8TbWBU__h",
    "FvA-QZmRU__r",
    "hAUkklVXU__6",
    "rFln-NFtVAAI",
    "UZomXVzoVAAR",
    "qp-n688CVAAc",
    "tGmGzrbsVAAf",
    "oFzCFS89VABM",
    "TlO1q-zlVABg"
   ],
   "name": "3_How-do-machines-understand language.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
